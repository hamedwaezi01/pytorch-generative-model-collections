{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from CGAN import CGAN\n",
    "from utils import generate_augmentation, imshow_normalized, AugmentedDataset\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torchmetrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2], [0, 1, 2], [0, 1, 2]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.tensor([[0],[0],[0]]), torch.tensor([[1,2],[1,2],[1,2]])), dim=1).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks architecture -------------\n",
      "generator(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=109, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=6272, bias=True)\n",
      "    (4): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (deconv): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Tanh()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 6688321\n",
      "discriminator(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(48, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 6607297\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class LOL(dict):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __getattr__(gan, attr):\n",
    "        return gan.data[attr]\n",
    "\n",
    "batch_size = 64\n",
    "input_size = 28\n",
    "num_classes = 47\n",
    "do_train = False\n",
    "\n",
    "\n",
    "args = LOL({\n",
    "    \"epoch\": 10,\n",
    "    \"batch_size\": 64,\n",
    "    \"save_dir\": \"models\",\n",
    "    \"result_dir\": \"results\",\n",
    "    \"dataset\": \"emnist\",\n",
    "    \"log_dir\": \"logs\",\n",
    "    \"gpu_mode\": True,\n",
    "    \"gan_type\": \"CGAN\",\n",
    "    \"input_size\": 28,\n",
    "    \"lrG\": 0.0002,\n",
    "    \"lrD\": 0.0002,\n",
    "    \"beta1\": 0.05,\n",
    "    \"beta2\": 0.99,\n",
    "    \"class_num\": 47,\n",
    "})\n",
    "### Load CGAN\n",
    "try:\n",
    "    gan = CGAN(args)\n",
    "    gan.load()\n",
    "except Exception as e:\n",
    "    print(\"Couldn't load the model\")\n",
    "    do_train = True\n",
    "    gan = CGAN(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already trained\n"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    gan.train()\n",
    "else:\n",
    "    print(\"already trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28\n",
    "num_classes = 47\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((input_size, input_size)), transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "original_trainset = datasets.EMNIST('data/emnist', train=True, download=True, transform=transform, split=\"bymerge\")\n",
    "\n",
    "counter = [0]*num_classes\n",
    "for l in original_trainset.targets:\n",
    "    k = int(l)\n",
    "    counter[k] += 1\n",
    "counter = np.array(counter)\n",
    "\n",
    "### Number of augmentation per label\n",
    "max_count = counter.max()\n",
    "median = np.median(counter)\n",
    "mean = counter.mean().round()\n",
    "diffs = np.int32(mean - counter)\n",
    "diffs[diffs < 0] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 10 count: 8439\n",
      "label: 11 count: 10976\n",
      "label: 12 count: 1887\n",
      "label: 13 count: 10244\n",
      "label: 14 count: 9925\n",
      "label: 15 count: 5752\n",
      "label: 16 count: 12316\n",
      "label: 17 count: 11753\n",
      "label: 18 count: 117\n",
      "label: 19 count: 9161\n",
      "label: 20 count: 9852\n",
      "label: 22 count: 3238\n",
      "label: 23 count: 6613\n",
      "label: 25 count: 4102\n",
      "label: 26 count: 12247\n",
      "label: 27 count: 9803\n",
      "label: 29 count: 5084\n",
      "label: 31 count: 7262\n",
      "label: 32 count: 7447\n",
      "label: 33 count: 9252\n",
      "label: 34 count: 7758\n",
      "label: 35 count: 9434\n",
      "label: 36 count: 4841\n",
      "label: 37 count: 9770\n",
      "label: 38 count: 4698\n",
      "label: 40 count: 12315\n",
      "label: 41 count: 11157\n",
      "label: 42 count: 6168\n",
      "label: 43 count: 3406\n",
      "label: 44 count: 11884\n",
      "label: 45 count: 790\n",
      "concatenation of datasets is consistent\n"
     ]
    }
   ],
   "source": [
    "### The augmentation itself\n",
    "data = torch.tensor([]).cuda()\n",
    "targets = torch.tensor([]).cuda()\n",
    "for label, diff in enumerate(diffs):\n",
    "    if diff == 0:\n",
    "        continue\n",
    "    print(f\"label: {label} count: {diff}\")\n",
    "    new = generate_augmentation(gan, label, diff)\n",
    "    data = torch.cat([data, new])\n",
    "    targets = torch.cat([targets, (torch.ones(diff)*label).cuda()])\n",
    "\n",
    "targets = targets.cpu().to(torch.int64)\n",
    "data = data.cpu().squeeze()\n",
    "data = ((data + 1)*128).to(torch.uint8)\n",
    "augmented_set = torch.cat((original_trainset.data, data))\n",
    "augmented_targets = torch.cat((original_trainset.targets ,targets))\n",
    "if augmented_set.shape[0] == original_trainset.data.shape[0] + data.shape[0]:\n",
    "    print(\"concatenation of datasets is consistent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = \"png\"\n",
    "augmented_set = augmented_set.to(torch.float)\n",
    "for index, image in tqdm(enumerate(augmented_set)):\n",
    "    fp = f\"data/augmented/cgan/{augmented_targets[index]}/{index}.{ext}\"\n",
    "    utils.save_image(image, fp=fp, format=ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/emnist/augmented/cgan.pkl\", \"wb\") as f:\n",
    "    torch.save(augmentd_set, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
